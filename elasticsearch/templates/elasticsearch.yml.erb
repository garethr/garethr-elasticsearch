##################### ElasticSearch Configuration  #####################
# Managed by Puppet
# DO NOT EDIT

################################### Cluster ###################################

# Cluster name identifies your cluster for auto-discovery. If you're running
# multiple clusters on the same network, make sure you're using unique names.
#
cluster.name: <%= scope.lookupvar('elasticsearch::params::cluster_name') %> 

#################################### Node #####################################

# Node names are generated dynamically on startup, so you're relieved
# from configuring them manually. You can tie this node to a specific name:
#
# node.name: "Franz Kafka"
node.name: <%= scope.lookupvar('::hostname') %>

# Every node can be configured to allow or deny being eligible as the master,
# and to allow or deny to store the data.
#
# Allow this node to be eligible as a master node (enabled by default):
#
node.master: <%= scope.lookupvar('elasticsearch::params::node_master') %>
#
# Allow this node to store data (enabled by default):
#
node.data: <%= scope.lookupvar('elasticsearch::params::node_data') %>

# A node can have generic attributes associated with it, which can later be used
# for customized shard allocation filtering, or allocation awareness. An attribute
# is a simple key value pair, similar to node.key: value, here is an example:
#
node.rack: <%= has_variable?('::rack') ? rack : '1' %>

#################################### Index ####################################

# Set the number of shards (splits) of an index (5 by default):
#
index.number_of_shards: <%= scope.lookupvar('elasticsearch::params::index_number_of_shards') %>

# Set the number of replicas (additional copies) of an index (1 by default):
#
index.number_of_replicas: <%= scope.lookupvar('elasticsearch::params::index_number_of_replicas') %>

# Node filter cache
indices.cache.filter.size: <%= scope.lookupvar('elasticsearch::params::indices_cache_filter_size') %>

# Stats API refresh interval
index.cache.stats.refresh_interval: <%= scope.lookupvar('elasticsearch::params::index_cache_stats_refresh_interval') %>

# Term index interval
index.term_index_interval: <%= scope.lookupvar('elasticsearch::params::index_term_index_interval') %>

# Index Buffer
indices.memory.index_buffer_size: <%= scope.lookupvar('elasticsearch::params::indicies_memory_index_buffer_size') %>

# Dynamic Mappings
index.mapper.dynamic: <%= scope.lookupvar('elasticsearch::params::index_mapper_dynamic') %>

# After how many operations to flush. Defaults to 5000
index.translog.flush_threshold_ops: <%= scope.lookupvar('elasticsearch::params::index_translog_flush_threshold_ops') %>

# Tiered Merge Policy
index.merge.policy.floor_segment: <%= scope.lookupvar('elasticsearch::params::index_merge_policy_floor_segment') %>
index.merge.policy.max_merged_segment: <%= scope.lookupvar('elasticsearch::params::index_merge_policy_max_merged_segment') %>
index.merge.policy.segments_per_tier: <%= scope.lookupvar('elasticsearch::params::index_merge_policy_segments_per_tier') %>

#################################### Paths ####################################

# Path to directory containing configuration (this file and logging.yml):
#
path.conf: <%= scope.lookupvar('elasticsearch::params::path_conf') %>

# Path to directory where to store index data allocated for this node.
#
path.data: <%= has_variable?('::data_volumes') ? data_volumes.split(',').join('/elasticsearch,') + '/elasticsearch' : '/tmp/elasticsearch' %>

# Path to temporary files:
#
path.work: <%= scope.lookupvar('elasticsearch::params::es_work_dir') %>

# Path to log files:
#
path.logs: <%= scope.lookupvar('elasticsearch::params::es_log_dir') %>

# Path to where plugins are installed:
#
path.plugins: <%= scope.lookupvar('elasticsearch::params::path_plugins') %>

################################### Memory ####################################

# ElasticSearch performs poorly when JVM starts swapping: you should ensure that
# it _never_ swaps.
#
# Set this property to true to lock the memory:
#
bootstrap.mlockall: <%= scope.lookupvar('elasticsearch::params::bootstrap_mlockall') %>

# Make sure that the ES_MIN_MEM and ES_MAX_MEM environment variables are set
# to the same value, and that the machine has enough memory to allocate
# for ElasticSearch, leaving enough memory for the operating system itself.
#
# You should also make sure that the ElasticSearch process is allowed to lock
# the memory, eg. by using `ulimit -l unlimited`.


############################## Network And HTTP ###############################

# ElasticSearch, by default, binds itself to the 0.0.0.0 address, and listens
# on port [9200-9300] for HTTP traffic and on port [9300-9400] for node-to-node
# communication. (the range means that if the port is busy, it will automatically
# try the next port).

# Set the bind address specifically (IPv4 or IPv6):
#
# network.bind_host: 192.168.0.1

# Set the address other nodes will use to communicate with this node. If not
# set, it is automatically derived. It must point to an actual IP address.
#
# network.publish_host: 192.168.0.1

# Set both 'bind_host' and 'publish_host':
#
# network.host: 192.168.0.1

# Set a custom port for the node to node communication (9300 by default):
#
transport.port: <%= scope.lookupvar('elasticsearch::params::transport_port') %>

# Enable compression for all communication between nodes (disabled by default):
#
# transport.tcp.compress: true
transport.tcp.compress: <%= scope.lookupvar('elasticsearch::params::transport_tcp_compress') %>

# Set a custom port to listen for HTTP traffic:
#
http.port: <%= scope.lookupvar('elasticsearch::params::http_port') %>

# Set a custom allowed content length:
#
http.max_content_length: <%= scope.lookupvar('elasticsearch::params::http_max_content_length') %>

# Disable HTTP completely:
#
http.enabled: <%= scope.lookupvar('elasticsearch::params::http_enabled') %>


################################### Mappings ###################################

# Turn off dynamic mapping
index.mapper.dynamic: <%= scope.lookupvar('elasticsearch::params::index_mapper_dynamic') %> 

################################### Gateway ###################################

# The gateway allows for persisting the cluster state between full cluster
# restarts. Every change to the state (such as adding an index) will be stored
# in the gateway, and when the cluster starts up for the first time,
# it will read its state from the gateway.

# There are several types of gateway implementations. For more information,
# see <http://elasticsearch.org/guide/reference/modules/gateway>.

# The default gateway type is the "local" gateway (recommended):
#
gateway.type: <%= scope.lookupvar('elasticsearch::params::gateway_type') %>

# Settings below control how and when to start the initial recovery process on
# a full cluster restart (to reuse as much local data as possible).

# Allow recovery process after N nodes in a cluster are up:
#
gateway.recover_after_nodes: <%= scope.lookupvar('elasticsearch::params::gateway_recover_after_nodes') %>

# Set the timeout to initiate the recovery process, once the N nodes
# from previous setting are up (accepts time value):
#
gateway.recover_after_time: <%= scope.lookupvar('elasticsearch::params::gateway_recovery_after_time') %>

# Set how many nodes are expected in this cluster. Once these N nodes
# are up, begin recovery process immediately:
#
gateway.expected_nodes: <%= scope.lookupvar('elasticsearch::params::gateway_excepted_nodes') %>

############################# Recovery Throttling #############################

# These settings allow to control the process of shards allocation between
# nodes during initial recovery, replica allocation, rebalancing,
# or when adding and removing nodes.

# Set the number of concurrent recoveries happening on a node:
#
# 1. During the initial recovery
#
cluster.routing.allocation.node_initial_primaries_recoveries: <%= scope.lookupvar('elasticsearch::params::cluster_routing_allocation_node_initial_primaries_recoveries') %>
#
# 2. During adding/removing nodes, rebalancing, etc
#
cluster.routing.allocation.node_concurrent_recoveries: <%= scope.lookupvar('elasticsearch::params::cluster_routing_allocation_concurrent_recoveries') %>

# Set to throttle throughput when recovering (eg. 100mb, by default unlimited):
#
indices.recovery.max_size_per_sec: <%= scope.lookupvar('elasticsearch::params::indices_recovery_max_size_per_sec') %>

# Set to limit the number of open concurrent streams when
# recovering a shard from a peer:
#
indices.recovery.concurrent_streams: <%= scope.lookupvar('elasticsearch::params::indices_recovery_concurrent_streams') %>


################################## Discovery ##################################

# Discovery infrastructure ensures nodes can be found within a cluster
# and master node is elected. Multicast discovery is the default.

# Set to ensure a node sees N other master eligible nodes to be considered
# operational within the cluster. Set this option to a higher value (2-4)
# for large clusters:
#
discovery.zen.minimum_master_nodes: <%= scope.lookupvar('elasticsearch::params::discovery_zen_minimum_master_nodes') %>

# Set the time to wait for ping responses from other nodes when discovering.
# Set this option to a higher value on a slow or congested network
# to minimize discovery failures:
#
discovery.zen.ping.timeout: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_timeout') %>

# 1. Disable multicast discovery (enabled by default):
#
discovery.zen.ping.multicast.enabled: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_multicast_enabled') %>
discovery.zen.ping.multicast.group: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_multicast_group') %>
discovery.zen.ping.multicast.port: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_multicast_port') %>
discovery.zen.ping.multicast.ttl: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_multicast_ttl') %>


# 2. Configure an initial list of master nodes in the cluster
#    to perform discovery when new nodes (master or data) are started:
#
discovery.zen.ping.unicast.enabled: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_unicast_enabled') %>
discovery.zen.ping.unicast.hosts: <%= scope.lookupvar('elasticsearch::params::discovery_zen_ping_unicast_hosts') %>

################################## Slow Log ##################################
# Shard level query and fetch threshold logging.

index.search.slowlog.level: <%= scope.lookupvar('elasticsearch::params::index_search_slowlog_level') %>
index.search.slowlog.threshold.query.warn: 2s
index.search.slowlog.threshold.query.info: 1s
index.search.slowlog.threshold.query.debug: 500ms
index.search.slowlog.threshold.query.trace: 1ms

index.search.slowlog.threshold.fetch.warn: 1s
index.search.slowlog.threshold.fetch.info: 500ms
index.search.slowlog.threshold.fetch.debug: 100ms
index.search.slowlog.threshold.fetch.trace: 1ms

## safety feature.  make it so we can't just delete everything by mistake
action.disable_delete_all_indices: true

index.term_index_divisor: <%= scope.lookupvar('elasticsearch::params::index_term_divisor') %>
